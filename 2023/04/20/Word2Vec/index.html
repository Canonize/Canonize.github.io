<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>更新Word2Vec模型的多种尝试 | Canoe</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="Word2Vec是一种广泛使用的自然语言处理技术，它可以将文本转换为向量形式，并且可以在向量空间中对这些向量进行操作，例如计算相似性、聚类等。在这篇文章中，将讲述更新Word2Vec模型的多种尝试。 Word2Vec简介Word2Vec是一种由Google于2013年发布的自然语言处理工具包。它可以将文本中的单词转换为向量形式，并且可以在向量空间中对这些向量进行操作。Word2Vec包括两种模型：">
<meta property="og:type" content="article">
<meta property="og:title" content="更新Word2Vec模型的多种尝试">
<meta property="og:url" content="http://example.com/2023/04/20/Word2Vec/index.html">
<meta property="og:site_name" content="Canoe">
<meta property="og:description" content="Word2Vec是一种广泛使用的自然语言处理技术，它可以将文本转换为向量形式，并且可以在向量空间中对这些向量进行操作，例如计算相似性、聚类等。在这篇文章中，将讲述更新Word2Vec模型的多种尝试。 Word2Vec简介Word2Vec是一种由Google于2013年发布的自然语言处理工具包。它可以将文本中的单词转换为向量形式，并且可以在向量空间中对这些向量进行操作。Word2Vec包括两种模型：">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2023-04-20T03:58:43.000Z">
<meta property="article:modified_time" content="2023-04-20T13:24:45.571Z">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="Canoe" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
<meta name="generator" content="Hexo 6.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Canoe</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-Word2Vec" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/04/20/Word2Vec/" class="article-date">
  <time class="dt-published" datetime="2023-04-20T03:58:43.000Z" itemprop="datePublished">2023-04-20</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      更新Word2Vec模型的多种尝试
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>Word2Vec是一种广泛使用的自然语言处理技术，它可以将文本转换为向量形式，并且可以在向量空间中对这些向量进行操作，例如计算相似性、聚类等。在这篇文章中，将讲述更新Word2Vec模型的多种尝试。</p>
<h2 id="Word2Vec简介"><a href="#Word2Vec简介" class="headerlink" title="Word2Vec简介"></a>Word2Vec简介</h2><p>Word2Vec是一种由Google于2013年发布的自然语言处理工具包。它可以将文本中的单词转换为向量形式，并且可以在向量空间中对这些向量进行操作。Word2Vec包括两种模型：CBOW和Skip-gram。</p>
<p>CBOW（Continuous Bag-of-Words）模型会尝试根据上下文单词来预测中心单词。Skip-gram模型则相反，它会尝试根据中心单词来预测上下文单词。在实践中，Skip-gram模型通常比CBOW模型更好。</p>
<h2 id="训练Word2Vec模型"><a href="#训练Word2Vec模型" class="headerlink" title="训练Word2Vec模型"></a>训练Word2Vec模型</h2><p>要训练Word2Vec模型，需要一个大型的文本语料库。可以使用Python中的gensim库来训练Word2Vec模型。首先，需要将文本分成单词，然后将单词列表传递给gensim.models.Word2Vec类的构造函数。</p>
<p>以下是一个简单的例子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> gensim.models <span class="keyword">import</span> Word2Vec</span><br><span class="line"></span><br><span class="line">sentences = [[<span class="string">&quot;cat&quot;</span>, <span class="string">&quot;say&quot;</span>, <span class="string">&quot;meow&quot;</span>], [<span class="string">&quot;dog&quot;</span>, <span class="string">&quot;say&quot;</span>, <span class="string">&quot;woof&quot;</span>]]</span><br><span class="line">model = Word2Vec(sentences, min_count=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<p>上面的代码将创建一个Word2Vec模型，用于训练由两个句子组成的语料库。min_count参数设置单词出现的最小次数。如果一个单词在语料库中出现的次数小于这个值，那么这个单词将被忽略。</p>
<p>可以使用以下代码来查看单词向量：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">vector = model.wv[<span class="string">&quot;cat&quot;</span>]</span><br><span class="line"><span class="built_in">print</span>(vector)</span><br></pre></td></tr></table></figure>

<p>也可以使用以下代码来查找与给定单词最相似的单词：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">similar_words = model.wv.most_similar(<span class="string">&quot;cat&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(similar_words)</span><br></pre></td></tr></table></figure>

<h2 id="更新Word2Vec模型"><a href="#更新Word2Vec模型" class="headerlink" title="更新Word2Vec模型"></a>更新Word2Vec模型</h2><p>在某些情况下，希望在不重新训练整个Word2Vec模型的情况下更新它。gensim库提供了两种更新Word2Vec模型的方法。</p>
<p>第一种方法是使用gensim.models.Word2Vec类的build_vocab()方法来构建新的单词表。然后，可以使用train()方法来更新模型。以下是一个简单的例子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model.build_vocab([[<span class="string">&quot;bird&quot;</span>, <span class="string">&quot;fly&quot;</span>, <span class="string">&quot;high&quot;</span>]], update=<span class="literal">True</span>)</span><br><span class="line">model.train([[<span class="string">&quot;bird&quot;</span>, <span class="string">&quot;fly&quot;</span>, <span class="string">&quot;high&quot;</span>]], total_examples=<span class="number">1</span>, epochs=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<p>上面的代码将向模型添加一个新的句子，然后更新模型。注意，这里需要设置update参数为True。</p>
<p>第二种方法是使用gensim.models.Word2Vec类的build_vocab()方法来构建新的单词表。然后，就可以使用gensim.models.KeyedVectors类的add_vectors()方法来添加新的单词向量。以下是一个简单的例子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model.build_vocab([[<span class="string">&quot;bird&quot;</span>, <span class="string">&quot;fly&quot;</span>, <span class="string">&quot;high&quot;</span>]], update=<span class="literal">True</span>)</span><br><span class="line">new_vector = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line">model.wv.add_vectors([<span class="string">&quot;bird&quot;</span>], [new_vector])</span><br></pre></td></tr></table></figure>

<p>上面的代码将添加一个新的单词向量，然后更新模型。</p>
<h2 id="Google-预训练的-Word2Vec-模型"><a href="#Google-预训练的-Word2Vec-模型" class="headerlink" title="Google 预训练的 Word2Vec 模型"></a>Google 预训练的 Word2Vec 模型</h2><p>Google 发布了一款基于 Google News 数据集的预训练 Word2Vec 模型，包含了 300 维向量，覆盖了 300 万个单词和短语。该模型可从此<a target="_blank" rel="noopener" href="https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz">链接</a>下载，二进制文件（GoogleNews-vectors-negative300.bin）解压后大小为 3.4 GB。</p>
<p>在 Python 代码中使用预训练模型需要使用 <code>gensim</code> 库中的 <code>KeyedVectors</code> 类：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> gensim.models <span class="keyword">import</span> KeyedVectors</span><br><span class="line"></span><br><span class="line">filename = <span class="string">&#x27;GoogleNews-vectors-negative300.bin&#x27;</span></span><br><span class="line">model = KeyedVectors.load_word2vec_format(filename, binary=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<p>使用预训练好的模型可以快速构建起权威的语料库，但在深入使用之后，经常会碰到词汇表缺失的问题，连”forgot”这种常用词，都不在词汇表中，无法进行匹配。</p>
<p>这是因为为了保证效率，Google 预训练的 Word2Vec 模型中并不会保留全部词汇，而是选择性的存储高频词汇，若需要将其用到不同的领域之中，需要对模型的词汇进行更新与微调。</p>
<p>一开始先尝试了手动地往Google 预训练的 Word2Vec 模型中补充缺失的词向量，但遇到了许多错误，查询资料后才发现：</p>
<p>预训练模型的一个缺点是，由于缺少隐藏权重、词汇频率和二叉树，无法继续训练，因此无法在预训练模型上进行迁移学习。</p>
<p>后来又顺着逆向的思维来看，既然预训练模型缺少信息，无法更新，那反过来可不可以用预训练模型来更新自己新建的模型呢？于是尝试使用 <code>intersect_word2vec_format</code> 方法替换自己模型中的词向量与预训练模型中的词向量：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">your_word2vec_model.intersect_word2vec_format(<span class="string">&#x27;GoogleNews-vectors-negative300.bin&#x27;</span>, lockf=<span class="number">1.0</span>, binary=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<p>虽然此方法不是迁移学习，但它非常类似。如果有一个小的自定义数据集，并想使用 Google 的预训练模型进行迁移学习，可以使用以下代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> gensim.models <span class="keyword">import</span> Word2Vec</span><br><span class="line"> </span><br><span class="line">sentences = [[<span class="string">&quot;坏&quot;</span>, <span class="string">&quot;机器人&quot;</span>], [<span class="string">&quot;好&quot;</span>, <span class="string">&quot;人类&quot;</span>], [<span class="string">&quot;是的&quot;</span>, <span class="string">&quot;这&quot;</span>, <span class="string">&quot;是&quot;</span>, <span class="string">&quot;Word2Vec&quot;</span>, <span class="string">&quot;模型&quot;</span>]]</span><br><span class="line"> </span><br><span class="line"><span class="comment"># size 选项需要设置为 300，以与 Google 的预训练模型相同</span></span><br><span class="line"> </span><br><span class="line">word2vec_model = Word2Vec(size=<span class="number">300</span>, window=<span class="number">5</span>, min_count=<span class="number">1</span>, workers=<span class="number">2</span>)</span><br><span class="line"> </span><br><span class="line">word2vec_model.build_vocab(sentences)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 将单词向量指定为 Google 预训练模型中的向量和上面定义的句子</span></span><br><span class="line"> </span><br><span class="line"><span class="comment"># lockf 必须设置为 1.0 才能允许继续训练</span></span><br><span class="line"> </span><br><span class="line">word2vec_model.intersect_word2vec_format(<span class="string">&#x27;./word2vec/GoogleNews-vectors-negative300.bin&#x27;</span>, lockf=<span class="number">1.0</span>, binary=<span class="literal">True</span>)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 使用自己的数据继续训练</span></span><br><span class="line"> </span><br><span class="line">word2vec_model.train(sentences, total_examples=<span class="number">3</span>, epochs=<span class="number">5</span>)</span><br></pre></td></tr></table></figure>

<p>此代码将词向量分配给 Google 预训练模型中的词汇表和上面定义的句子，然后使用自己的数据继续训练。 <code>size</code> 选项需要设置为 300，以与 Google 的预训练模型相同。 <code>lockf</code> 选项需要设置为 1.0 才能允许继续训练。</p>
<p>因为我使用 <code>gensim</code>是 4.0.1 版本的 <code>Word2Vec</code> 模型时，还遇到以下错误：</p>
<figure class="highlight delphi"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">IndexError: <span class="keyword">index</span> <span class="number">0</span> <span class="keyword">is</span> <span class="keyword">out</span> <span class="keyword">of</span> bounds <span class="keyword">for</span> axis <span class="number">0</span> <span class="keyword">with</span> size <span class="number">0</span></span><br></pre></td></tr></table></figure>

<p>在插入向量之前，还需要手动设定一下<code>lockf</code> 值：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.wv.vectors_lockf = np.ones(<span class="built_in">len</span>(model.wv), dtype=REAL)</span><br></pre></td></tr></table></figure>

<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>在这篇文章中，尝试了多种训练和更新Word2Vec模型的方法。虽然最后以新训练模型成功补上了缺失的词汇，并利用Google News的预训练模型进行了迁移学习，但还是达不到词汇量与准确度上的两全其美。</p>
<p>查资料的过程中发现了Doc2vec，说是支持在线训练，并能自动推断未知词汇，倒是能满足需求的样子，下一步可能会去看看它的使用。</p>
<p>参考资料：</p>
<p>Gensin教程：<a target="_blank" rel="noopener" href="https://rutumulkar.com/blog/2015/word2vec/">https://rutumulkar.com/blog/2015/word2vec/</a></p>
<p>Google预训练模型代码：<a target="_blank" rel="noopener" href="https://code.google.com/archive/p/word2vec/">https://code.google.com/archive/p/word2vec/</a></p>
<p>更新W2V模型：<a target="_blank" rel="noopener" href="https://phdstatsphys.wordpress.com/2018/12/27/word2vec-how-to-train-and-update-it/">https://phdstatsphys.wordpress.com/2018/12/27/word2vec-how-to-train-and-update-it/</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2023/04/20/Word2Vec/" data-id="clgp5nb7p0000fsubfyatgrbp" data-title="更新Word2Vec模型的多种尝试" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2023/04/28/BERT/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          使用BERT进行简单的文本分类
        
      </div>
    </a>
  
  
    <a href="/2023/04/17/frontmatter/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">frontmatter</div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/06/">June 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/04/">April 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/03/">March 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/02/">February 2023</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2023/06/24/dexdump/">新版本ColorOS使用dexdump脱壳遇到的问题及解决</a>
          </li>
        
          <li>
            <a href="/2023/06/16/ICC/">现有Android ICC静态分析工具总结</a>
          </li>
        
          <li>
            <a href="/2023/06/04/widget/">根据 XML 文件，计算组件在布局中的位置</a>
          </li>
        
          <li>
            <a href="/2023/04/28/BERT/">使用BERT进行简单的文本分类</a>
          </li>
        
          <li>
            <a href="/2023/04/20/Word2Vec/">更新Word2Vec模型的多种尝试</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2023 John Doe<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.4.1.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>